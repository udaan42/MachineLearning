{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findCommunities(filename):\n",
    "    communities = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        filereader = csv.reader(csvfile)\n",
    "        j = 0\n",
    "        for i in filereader:\n",
    "            if j > 0:\n",
    "                if i[1] not in communities:\n",
    "                    communities.append(i[1])\n",
    "            j+=1\n",
    "    return communities\n",
    "def extractData(filename,communities,addstate = False,addcommunity = False):\n",
    "    features = []\n",
    "    xPositive=[]\n",
    "    yPositive=[]\n",
    "    xNegative=[]\n",
    "    yNegative =[]\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        filereader = csv.reader(csvfile)\n",
    "        j = 0\n",
    "        for i in filereader:\n",
    "            if j > 0:\n",
    "                data = i[5:len(i)-1]\n",
    "                while '?' in data:\n",
    "                    data[data.index('?')] = 0\n",
    "                if addstate:\n",
    "                    state = [0.0]*56\n",
    "                    state[int(i[0])-1] = 1.0\n",
    "                    data = data + state\n",
    "                    features = features + [\"state\"+str(i) for i in range(56)]\n",
    "                if addcommunity:\n",
    "                    tmp = [0.0]*len(communities)\n",
    "                    tmp[communities.index(i[1])] = 1.0\n",
    "                    data = data + tmp\n",
    "                    features = features + communities\n",
    "                vect = np.array(data)\n",
    "                #vect = np.array(i[3:len(i)-1])\n",
    "                #x.append(vect.astype(np.float))\n",
    "                if float(i[-1]) > 0.1:\n",
    "                    xPositive.append(vect.astype(np.float))\n",
    "                    yPositive.append(1)\n",
    "                else:\n",
    "                    xNegative.append(vect.astype(np.float))\n",
    "                    yNegative.append(0)\n",
    "            else:\n",
    "                features = i[5:len(i)-1]\n",
    "            j+=1\n",
    "        \"\"\"yPositive = np.array(yPositive)\n",
    "        xPositive = np.array(xPositive)\n",
    "        yNegative = np.array(yNegative)\n",
    "        xNegative = np.array(xNegative)\"\"\"\n",
    "        features = np.array(features)\n",
    "        indxP = int(len(xPositive)*.6)\n",
    "        indxN = int(len(xNegative)*.6)\n",
    "        xTrain =np.array(xPositive[:indxP] + xNegative[:indxN])\n",
    "        yTrain = np.array(yPositive[:indxP] + yNegative[:indxN])\n",
    "        xTest = np.array(xPositive[indxP:] + xNegative[indxN:])\n",
    "        yTest = np.array(yPositive[indxP:] + yNegative[indxN:])\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "        return xTrain,yTrain,xTest,yTest,features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Label Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcualtePercentage(labels):\n",
    "    n = len(labels)\n",
    "    sumTrue = sum(labels)*1.0\n",
    "    sumFalse = (n - sumTrue)*1.0\n",
    "    return sumTrue/n,sumFalse/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decisionTree():\n",
    "    return tree.DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusionMatrix(true,predicted,labels = [1,0]):\n",
    "    return confusion_matrix(true,predicted,labels)\n",
    "\n",
    "def find_confusion_matrix(actual,predicted,clabels):\n",
    "    cm= []\n",
    "    for i in clabels:\n",
    "        tmp =[0]*len(clabels)\n",
    "        \n",
    "        for j in range(len(actual)):\n",
    "            if actual[j]== i and actual[j] == predicted[j]:\n",
    "                tmp[clabels.index(i)] += 1\n",
    "            elif actual[j]== i and actual[j] != predicted[j]:\n",
    "                tmp[clabels.index(predicted[j])] += 1\n",
    "        cm.append(tmp)\n",
    "    return np.array(cm)\n",
    "def find_accuracy(matrix):\n",
    "    return np.trace(matrix)*1.0/np.sum(matrix)\n",
    "def find_precision(matrix):\n",
    "    pres = []\n",
    "    x = np.sum(matrix,axis=0)\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                pres.append(matrix[i][j]*1.0/x[i])\n",
    "    return pres\n",
    "def find_recall(matrix):\n",
    "    rec = []\n",
    "    x = np.sum(matrix,axis=1)\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                rec.append(matrix[i][j]*1.0/x[i])\n",
    "    return rec\n",
    "def evaluation(acutal,predicted,clabels=[1,0]):\n",
    "    confmatrix = find_confusion_matrix(acutal,predicted,clabels)\n",
    "    print (\"Confusion Matrix\")\n",
    "    print (confmatrix)\n",
    "    accuracy = find_accuracy(confmatrix)\n",
    "    print (\"Accuracy\", accuracy)\n",
    "    precision = find_precision(confmatrix)\n",
    "    print (\"Precision\", precision)\n",
    "    recall = find_recall(confmatrix)\n",
    "    print (\"Recall\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_cross_validation(X, y,clf, n_folds=5):\n",
    "    cv = KFold(len(y), n_folds, shuffle=True)\n",
    "    accuracies = []\n",
    "    i = 1\n",
    "    for train_ind, test_ind in cv: \n",
    "        clf.fit(X[train_ind], y[train_ind])\n",
    "        predictions = clf.predict(X[test_ind])\n",
    "        print (\"Fold %d Evaluation\" %i)\n",
    "        i +=1\n",
    "        evaluation(y[test_ind],predictions)\n",
    "        print (\"\\n\")\n",
    "        accuracies.append(accuracy_score(y[test_ind], predictions))\n",
    "    avg = np.mean(accuracies)\n",
    "    print (\"The average Accuracy is \", avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = 'C:\\\\Users\\\\ar1\\\\Documents\\ML\\\\Project\\\\Crime Prediction Data(1)\\\\Crime Prediction Data\\\\communities-crime-full.csv'\n",
    "distintCommunities = findCommunities(filename)\n",
    "XTrain,YTrain,XTest,YTest,Features = extractData(filename, distintCommunities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Percentage (0.62761506276150625, 0.3723849372384937)\n",
      "Test Percentage (0.62703379224030042, 0.37296620775969963)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train Percentage\",calcualtePercentage(YTrain))\n",
    "print (\"Test Percentage\",calcualtePercentage(YTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[411  90]\n",
      " [111 187]]\n",
      "Accuracy 0.748435544431\n",
      "Precision [0.78735632183908044, 0.67509025270758127]\n",
      "Recall [0.82035928143712578, 0.62751677852348997]\n"
     ]
    }
   ],
   "source": [
    "model= decisionTree()\n",
    "model.fit(XTrain,YTrain)\n",
    "predictedY=model.predict(XTest)\n",
    "evaluation(YTest,predictedY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Fold Cross Validation on Default DecisionTree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Evaluation\n",
      "Confusion Matrix\n",
      "[[50 16]\n",
      " [18 36]]\n",
      "Accuracy 0.716666666667\n",
      "Precision [0.73529411764705888, 0.69230769230769229]\n",
      "Recall [0.75757575757575757, 0.66666666666666663]\n",
      "\n",
      "\n",
      "Fold 2 Evaluation\n",
      "Confusion Matrix\n",
      "[[58 16]\n",
      " [15 31]]\n",
      "Accuracy 0.741666666667\n",
      "Precision [0.79452054794520544, 0.65957446808510634]\n",
      "Recall [0.78378378378378377, 0.67391304347826086]\n",
      "\n",
      "\n",
      "Fold 3 Evaluation\n",
      "Confusion Matrix\n",
      "[[65 14]\n",
      " [14 27]]\n",
      "Accuracy 0.766666666667\n",
      "Precision [0.82278481012658233, 0.65853658536585369]\n",
      "Recall [0.82278481012658233, 0.65853658536585369]\n",
      "\n",
      "\n",
      "Fold 4 Evaluation\n",
      "Confusion Matrix\n",
      "[[52 14]\n",
      " [15 39]]\n",
      "Accuracy 0.758333333333\n",
      "Precision [0.77611940298507465, 0.73584905660377353]\n",
      "Recall [0.78787878787878785, 0.72222222222222221]\n",
      "\n",
      "\n",
      "Fold 5 Evaluation\n",
      "Confusion Matrix\n",
      "[[69 15]\n",
      " [ 9 27]]\n",
      "Accuracy 0.8\n",
      "Precision [0.88461538461538458, 0.6428571428571429]\n",
      "Recall [0.8214285714285714, 0.75]\n",
      "\n",
      "\n",
      "Fold 6 Evaluation\n",
      "Confusion Matrix\n",
      "[[60 18]\n",
      " [17 24]]\n",
      "Accuracy 0.705882352941\n",
      "Precision [0.77922077922077926, 0.5714285714285714]\n",
      "Recall [0.76923076923076927, 0.58536585365853655]\n",
      "\n",
      "\n",
      "Fold 7 Evaluation\n",
      "Confusion Matrix\n",
      "[[58  8]\n",
      " [17 36]]\n",
      "Accuracy 0.789915966387\n",
      "Precision [0.77333333333333332, 0.81818181818181823]\n",
      "Recall [0.87878787878787878, 0.67924528301886788]\n",
      "\n",
      "\n",
      "Fold 8 Evaluation\n",
      "Confusion Matrix\n",
      "[[59 14]\n",
      " [16 30]]\n",
      "Accuracy 0.747899159664\n",
      "Precision [0.78666666666666663, 0.68181818181818177]\n",
      "Recall [0.80821917808219179, 0.65217391304347827]\n",
      "\n",
      "\n",
      "Fold 9 Evaluation\n",
      "Confusion Matrix\n",
      "[[63 18]\n",
      " [15 23]]\n",
      "Accuracy 0.72268907563\n",
      "Precision [0.80769230769230771, 0.56097560975609762]\n",
      "Recall [0.77777777777777779, 0.60526315789473684]\n",
      "\n",
      "\n",
      "Fold 10 Evaluation\n",
      "Confusion Matrix\n",
      "[[67 16]\n",
      " [16 20]]\n",
      "Accuracy 0.731092436975\n",
      "Precision [0.80722891566265065, 0.55555555555555558]\n",
      "Recall [0.80722891566265065, 0.55555555555555558]\n",
      "\n",
      "\n",
      "The average Accuracy is  0.748081232493\n"
     ]
    }
   ],
   "source": [
    "do_cross_validation(XTrain,YTrain,model,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 important features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PctKids2Par' 'racePctWhite' 'racePctHisp' 'PctOccupManu' 'MedYrHousBuilt'\n",
      " 'MalePctDivorce' 'PctBornSameState' 'PctImmigRec10' 'PctHousLess3BR'\n",
      " 'numbUrban']\n"
     ]
    }
   ],
   "source": [
    "coef = model.feature_importances_\n",
    "topindx = np.argsort(coef)[::-1][:10]\n",
    "print (Features[topindx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
