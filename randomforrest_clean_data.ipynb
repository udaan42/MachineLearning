{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findCommunities(filename):\n",
    "    communities = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        filereader = csv.reader(csvfile)\n",
    "        j = 0\n",
    "        for i in filereader:\n",
    "            if j > 0:\n",
    "                if i[1] not in communities:\n",
    "                    communities.append(i[1])\n",
    "            j+=1\n",
    "    return communities\n",
    "def extractData(filename,communities,addstate = False,addcommunity = False):\n",
    "    features = []\n",
    "    xPositive=[]\n",
    "    yPositive=[]\n",
    "    xNegative=[]\n",
    "    yNegative =[]\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        filereader = csv.reader(csvfile)\n",
    "        j = 0\n",
    "        for i in filereader:\n",
    "            if j > 0:\n",
    "                data = i[3:len(i)-1]\n",
    "                if addstate:\n",
    "                    state = [0.0]*56\n",
    "                    state[int(i[0])-1] = 1.0\n",
    "                    data = data + state\n",
    "                    features = features + [\"state\"+str(i) for i in range(56)]\n",
    "                if addcommunity:\n",
    "                    tmp = [0.0]*len(communities)\n",
    "                    tmp[communities.index(i[1])] = 1.0\n",
    "                    data = data + tmp\n",
    "                    features = features + communities\n",
    "                vect = np.array(data)\n",
    "                #vect = np.array(i[3:len(i)-1])\n",
    "                #x.append(vect.astype(np.float))\n",
    "                if float(i[-1]) > 0.1:\n",
    "                    xPositive.append(vect.astype(np.float))\n",
    "                    yPositive.append(1)\n",
    "                else:\n",
    "                    xNegative.append(vect.astype(np.float))\n",
    "                    yNegative.append(0)\n",
    "            else:\n",
    "                features = i[3:len(i)-1]\n",
    "            j+=1\n",
    "        \"\"\"yPositive = np.array(yPositive)\n",
    "        xPositive = np.array(xPositive)\n",
    "        yNegative = np.array(yNegative)\n",
    "        xNegative = np.array(xNegative)\"\"\"\n",
    "        features = np.array(features)\n",
    "        indxP = int(len(xPositive)*.6)\n",
    "        indxN = int(len(xNegative)*.6)\n",
    "        xTrain =np.array(xPositive[:indxP] + xNegative[:indxN])\n",
    "        yTrain = np.array(yPositive[:indxP] + yNegative[:indxN])\n",
    "        xTest = np.array(xPositive[indxP:] + xNegative[indxN:])\n",
    "        yTest = np.array(yPositive[indxP:] + yNegative[indxN:])\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "        return xTrain,yTrain,xTest,yTest,features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Label Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcualtePercentage(labels):\n",
    "    n = len(labels)\n",
    "    sumTrue = sum(labels)*1.0\n",
    "    sumFalse = (n - sumTrue)*1.0\n",
    "    return sumTrue/n,sumFalse/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomForest():\n",
    "    return RandomForestClassifier.RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, \n",
    "                                       min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', \n",
    "                                       max_leaf_nodes=None, min_impurity_split=1e-07, bootstrap=True, oob_score=False, \n",
    "                                       n_jobs=1, random_state=None, verbose=0, warm_start=False, class_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusionMatrix(true,predicted,labels = [1,0]):\n",
    "    return confusion_matrix(true,predicted,labels)\n",
    "\n",
    "def find_confusion_matrix(actual,predicted,clabels):\n",
    "    cm= []\n",
    "    for i in clabels:\n",
    "        tmp =[0]*len(clabels)\n",
    "        \n",
    "        for j in range(len(actual)):\n",
    "            if actual[j]== i and actual[j] == predicted[j]:\n",
    "                tmp[clabels.index(i)] += 1\n",
    "            elif actual[j]== i and actual[j] != predicted[j]:\n",
    "                tmp[clabels.index(predicted[j])] += 1\n",
    "        cm.append(tmp)\n",
    "    return np.array(cm)\n",
    "def find_accuracy(matrix):\n",
    "    return np.trace(matrix)*1.0/np.sum(matrix)\n",
    "def find_precision(matrix):\n",
    "    pres = []\n",
    "    x = np.sum(matrix,axis=0)\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                pres.append(matrix[i][j]*1.0/x[i])\n",
    "    return pres\n",
    "def find_recall(matrix):\n",
    "    rec = []\n",
    "    x = np.sum(matrix,axis=1)\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                rec.append(matrix[i][j]*1.0/x[i])\n",
    "    return rec\n",
    "def evaluation(acutal,predicted,clabels=[1,0]):\n",
    "    confmatrix = find_confusion_matrix(acutal,predicted,clabels)\n",
    "    print (\"Confusion Matrix\")\n",
    "    print (confmatrix)\n",
    "    accuracy = find_accuracy(confmatrix)\n",
    "    print (\"Accuracy\", accuracy)\n",
    "    precision = find_precision(confmatrix)\n",
    "    print (\"Precision\", precision)\n",
    "    recall = find_recall(confmatrix)\n",
    "    print (\"Recall\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_cross_validation(X, y,clf, n_folds=5):\n",
    "    cv = KFold(len(y), n_folds, shuffle=True)\n",
    "    accuracies = []\n",
    "    i = 1\n",
    "    for train_ind, test_ind in cv: \n",
    "        clf.fit(X[train_ind], y[train_ind])\n",
    "        predictions = clf.predict(X[test_ind])\n",
    "        print (\"Fold %d Evaluation\" %i)\n",
    "        i +=1\n",
    "        evaluation(y[test_ind],predictions)\n",
    "        print (\"\\n\")\n",
    "        accuracies.append(accuracy_score(y[test_ind], predictions))\n",
    "    avg = np.mean(accuracies)\n",
    "    print (\"The average Accuracy is \", avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'C:\\\\Users\\\\ar1\\\\Documents\\ML\\\\Project\\\\Crime Prediction Data(1)\\\\Crime Prediction Data\\\\communities-crime-clean.csv'\n",
    "distintCommunities = findCommunities(filename)\n",
    "XTrain,YTrain,XTest,YTest,Features = extractData(filename, distintCommunities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Percentage (0.62761506276150625, 0.3723849372384937)\n",
      "Test Percentage (0.62656641604010022, 0.37343358395989973)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train Percentage\",calcualtePercentage(YTrain))\n",
    "print (\"Test Percentage\",calcualtePercentage(YTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[399 101]\n",
      " [ 69 229]]\n",
      "Accuracy 0.786967418546\n",
      "Precision [0.85256410256410253, 0.69393939393939397]\n",
      "Recall [0.79800000000000004, 0.76845637583892612]\n"
     ]
    }
   ],
   "source": [
    "model= RandomForestClassifier(max_depth=None, min_samples_split=2,n_estimators=10)\n",
    "model.fit(XTrain,YTrain)\n",
    "predictedY=model.predict(XTest)\n",
    "evaluation(YTest,predictedY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Fold Cross Validation on Default DecisionTree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Evaluation\n",
      "Confusion Matrix\n",
      "[[62 10]\n",
      " [12 36]]\n",
      "Accuracy 0.816666666667\n",
      "Precision [0.83783783783783783, 0.78260869565217395]\n",
      "Recall [0.86111111111111116, 0.75]\n",
      "\n",
      "\n",
      "Fold 2 Evaluation\n",
      "Confusion Matrix\n",
      "[[66 14]\n",
      " [ 4 36]]\n",
      "Accuracy 0.85\n",
      "Precision [0.94285714285714284, 0.71999999999999997]\n",
      "Recall [0.82499999999999996, 0.90000000000000002]\n",
      "\n",
      "\n",
      "Fold 3 Evaluation\n",
      "Confusion Matrix\n",
      "[[62 11]\n",
      " [ 9 38]]\n",
      "Accuracy 0.833333333333\n",
      "Precision [0.87323943661971826, 0.77551020408163263]\n",
      "Recall [0.84931506849315064, 0.80851063829787229]\n",
      "\n",
      "\n",
      "Fold 4 Evaluation\n",
      "Confusion Matrix\n",
      "[[57 13]\n",
      " [10 40]]\n",
      "Accuracy 0.808333333333\n",
      "Precision [0.85074626865671643, 0.75471698113207553]\n",
      "Recall [0.81428571428571428, 0.80000000000000004]\n",
      "\n",
      "\n",
      "Fold 5 Evaluation\n",
      "Confusion Matrix\n",
      "[[56 10]\n",
      " [ 8 46]]\n",
      "Accuracy 0.85\n",
      "Precision [0.875, 0.8214285714285714]\n",
      "Recall [0.84848484848484851, 0.85185185185185186]\n",
      "\n",
      "\n",
      "Fold 6 Evaluation\n",
      "Confusion Matrix\n",
      "[[69  9]\n",
      " [ 9 32]]\n",
      "Accuracy 0.848739495798\n",
      "Precision [0.88461538461538458, 0.78048780487804881]\n",
      "Recall [0.88461538461538458, 0.78048780487804881]\n",
      "\n",
      "\n",
      "Fold 7 Evaluation\n",
      "Confusion Matrix\n",
      "[[62 10]\n",
      " [17 30]]\n",
      "Accuracy 0.773109243697\n",
      "Precision [0.78481012658227844, 0.75]\n",
      "Recall [0.86111111111111116, 0.63829787234042556]\n",
      "\n",
      "\n",
      "Fold 8 Evaluation\n",
      "Confusion Matrix\n",
      "[[71 11]\n",
      " [12 25]]\n",
      "Accuracy 0.806722689076\n",
      "Precision [0.85542168674698793, 0.69444444444444442]\n",
      "Recall [0.86585365853658536, 0.67567567567567566]\n",
      "\n",
      "\n",
      "Fold 9 Evaluation\n",
      "Confusion Matrix\n",
      "[[69 13]\n",
      " [ 4 33]]\n",
      "Accuracy 0.857142857143\n",
      "Precision [0.9452054794520548, 0.71739130434782605]\n",
      "Recall [0.84146341463414631, 0.89189189189189189]\n",
      "\n",
      "\n",
      "Fold 10 Evaluation\n",
      "Confusion Matrix\n",
      "[[60 15]\n",
      " [ 9 35]]\n",
      "Accuracy 0.798319327731\n",
      "Precision [0.86956521739130432, 0.69999999999999996]\n",
      "Recall [0.80000000000000004, 0.79545454545454541]\n",
      "\n",
      "\n",
      "The average Accuracy is  0.824236694678\n"
     ]
    }
   ],
   "source": [
    "do_cross_validation(XTrain,YTrain,model,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 important features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['racePctWhite' 'PctKids2Par' 'PctIlleg' 'PctPersDenseHous' 'NumIlleg'\n",
      " 'TotalPctDiv' 'PctYoungKids2Par' 'pctWInvInc' 'medFamInc' 'PctHousOwnOcc']\n"
     ]
    }
   ],
   "source": [
    "coef = model.feature_importances_\n",
    "topindx = np.argsort(coef)[::-1][:10]\n",
    "print (Features[topindx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
